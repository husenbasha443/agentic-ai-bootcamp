{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Genrate 10 Interview questions besed on user topicsm",
   "id": "f1324d53cc3327d0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-20T10:53:15.135715300Z",
     "start_time": "2025-12-20T10:53:14.556313100Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:56:08.853920100Z",
     "start_time": "2025-12-20T10:56:07.644970300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Generate 10 interview questions based on {topic}\"\"\"\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt|model|parser\n",
    "result = chain.invoke({\"topic\":\"Agentic AI Interview Questions\"})\n",
    "result"
   ],
   "id": "dea55c3f3daa73e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are 10 interview questions based on Agentic AI concepts:\\n\\n1. **Design an Agent's Goal-Setting Process**: \\nImagine you're building a conversational AI agent to provide customer support. Describe how you would design the goal-setting process for this agent, and how it would adapt to changing customer needs.\\n\\n2. **Explain the Difference Between Utility and Value**:\\nCan you explain the difference between utility and value in the context of an AI agent's decision-making process? How would an agent prioritize between these two concepts to make the most effective decisions?\\n\\n3. **Design a Plan for Handling Conflicting Goals**:\\nSuppose an AI agent is tasked with both optimizing customer satisfaction and minimizing operational costs. Describe how you would design a plan for handling conflicting goals, and how the agent would make trade-offs between them.\\n\\n4. **Describe a Situation Where an Agent Would Need to Reason About Intentionality**:\\nCan you describe a situation where an AI agent would need to reason about intentionality (i.e., understanding the goals and motivations of another entity)? How would the agent use this reasoning to make more effective decisions?\\n\\n5. **Design a System for Evaluating an Agent's Self-Improvement Progress**:\\nImagine you're building a self-improving AI agent that learns from its interactions with users. Describe how you would design a system for evaluating the agent's self-improvement progress, and how the agent would use this feedback to optimize its own behavior.\\n\\n6. **Explain How an Agent Would Use Causal Reasoning to Understand the Effects of Its Actions**:\\nCan you explain how an AI agent would use causal reasoning to understand the effects of its actions on the world? How would the agent use this understanding to make more informed decisions?\\n\\n7. **Design a Plan for Handling Uncertain or Unreliable Data**:\\nSuppose an AI agent is tasked with making decisions based on uncertain or unreliable data. Describe how you would design a plan for handling this type of data, and how the agent would make decisions in the face of uncertainty.\\n\\n8. **Describe a Situation Where an Agent Would Need to Reason About Social Norms**:\\nCan you describe a situation where an AI agent would need to reason about social norms (e.g., understanding what is considered polite or impolite behavior in a particular culture)? How would the agent use this reasoning to make more effective decisions?\\n\\n9. **Design a System for Evaluating an Agent's Ability to Form Intentions**:\\nImagine you're building an AI agent that can form and pursue its own intentions. Describe how you would design a system for evaluating the agent's ability to form intentions, and how the agent would use this evaluation to optimize its behavior.\\n\\n10. **Explain How an Agent Would Use Epistemic Reasoning to Update Its Beliefs**:\\nCan you explain how an AI agent would use epistemic reasoning to update its beliefs based on new information or experiences? How would the agent use this reasoning to make more informed decisions?\\n\\nThese questions are designed to test your understanding of agentic AI concepts, such as goal-setting, intentionality, self-improvement, and epistemic reasoning.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
